{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def clean_span(span):\n",
    "    \"\"\"\n",
    "    Cleans the given span string by ensuring balanced quotes and removing unwanted commas.\n",
    "\n",
    "    Args:\n",
    "        span (str): The span string to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned span string.\n",
    "    \"\"\"\n",
    "    span = span.strip()\n",
    "    if span.endswith('\"],') or span.endswith('\"]'):\n",
    "        span = span.rstrip('\"],').rstrip('\"]') + '\"'\n",
    "    return span\n",
    "\n",
    "def parse_attribute_spans(response_str):\n",
    "    \"\"\"\n",
    "    Parses the attribute spans from the given string and returns a dictionary.\n",
    "\n",
    "    Args:\n",
    "        response_str (str): The response string containing the attribute spans.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with attributes as keys and lists of strings as values.\n",
    "    \"\"\"\n",
    "    attributes = [\"Cinematography\", \"Direction\", \"Story\", \"Characters\", \"Production Design\", \"Unique Concept\", \"Emotions\"]\n",
    "    spans = {attr: [] for attr in attributes}\n",
    "\n",
    "    # Remove the surrounding curly braces and split the response into lines\n",
    "    lines = response_str.strip()[1:-1].strip().splitlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if \":\" in line:\n",
    "            parts = line.split(\":\", 1)\n",
    "            attr = parts[0].strip()\n",
    "            if attr in attributes:\n",
    "                # Remove the surrounding square brackets and split by comma\n",
    "                span_list_str = parts[1].strip().strip(\"[]\").strip()\n",
    "                if span_list_str:\n",
    "                    # Split by comma but handle cases where there might be commas within strings\n",
    "                    spans[attr] = [clean_span(item.strip().strip('\"').strip()) for item in span_list_str.split('\", ') if item.strip().strip('\"').strip() and item != ',']\n",
    "    \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18559</th>\n",
       "      <td>well i wasn't sure what the film was going to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18560</th>\n",
       "      <td>I have a lot of time for all the Columbo films...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18561</th>\n",
       "      <td>YETI deserves the 8 star rating because it is ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18562</th>\n",
       "      <td>I am and have been a serious collector of Chri...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18563</th>\n",
       "      <td>This year's Royal Rumble wasn't really bad, bu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31082 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "18559  well i wasn't sure what the film was going to ...  positive\n",
       "18560  I have a lot of time for all the Columbo films...  positive\n",
       "18561  YETI deserves the 8 star rating because it is ...  positive\n",
       "18562  I am and have been a serious collector of Chri...  negative\n",
       "18563  This year's Royal Rumble wasn't really bad, bu...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[31082 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Labeling Dataset\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import os, json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "apikey = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=apikey)\n",
    "\n",
    "df = pd.read_csv(\"../data/IMDB Dataset.csv\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "reviews = list(df[\"review\"][18500:])\n",
    "df[18500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labeling Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import os, json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "apikey = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=apikey)\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "You are an assistant who gives for specific attributes. The attributes are Cinematography, Direction, Story, Characters, Production Design, Unique Concept, and Emotions. \n",
    "\n",
    "YOUR INPUT WOULD BE LIKE THIS:\n",
    "Review: \"The cinematography was stunning, but the story was weak. I loved the movie. There wasn't anything unique in the movie. characters could've been better tho.\"\n",
    "\n",
    "YOU MUST FOLLOW THE OUTPUT FORMAT GIVEN BELOW. DON'T WRITE ANYTHING ELSE:\n",
    "{\n",
    "Cinematography: [list of strings with chunks where cinematography is discussed],\n",
    "Direction: [list of strings with chunks where direction is discussed],\n",
    "Story: [list of strings with chunks where story is discussed],\n",
    "Characters: [list of strings with chunks where characters are discussed],\n",
    "Production Design: [list of strings with chunks where production design is discussed],\n",
    "Unique Concept: [list of strings with chunks where unique concept is discussed],\n",
    "Other: [list of strings that mentions other things related to movie]\n",
    "}\n",
    "\n",
    "if something is not discussed, add empty list infront of it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Define the attributes\n",
    "attributes = [\"Cinematography\", \"Direction\", \"Story\", \"Characters\", \"Production Design\", \"Unique Concept\", \"Emotions\"]\n",
    "\n",
    "def get_sentiment_spans(review):\n",
    "    prompt = \"Label the following review below:\" + f\"\\nReview: {review}\\n\"\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content.strip()    \n",
    "    # Manually parse the response to extract spans\n",
    "    spans = parse_attribute_spans(response)\n",
    "    return spans\n",
    "\n",
    "def label_dataset_and_save(reviews, output_file, checkpoint_file):\n",
    "    labeled_data = []\n",
    "    start_index = 0\n",
    "    \n",
    "    # Check if checkpoint exists\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as file:\n",
    "            start_index = int(file.read().strip())\n",
    "    \n",
    "    for i in range(start_index, len(reviews)):\n",
    "        review = reviews[i]\n",
    "        spans = get_sentiment_spans(review)\n",
    "        labeled_data.append({\"review\": review, **spans})\n",
    "        \n",
    "        # Save in chunks of 100 reviews\n",
    "        if (i + 1) % 100 == 0 or (i + 1) == len(reviews):\n",
    "            with open(output_file, 'a') as file:\n",
    "                json.dump(labeled_data, file, indent=4)\n",
    "            labeled_data = []\n",
    "            with open(checkpoint_file, 'w') as file:\n",
    "                file.write(str(i + 1))\n",
    "            print(f\"Processed and saved {i + 1} reviews\")\n",
    "\n",
    "# Label the dataset and save continuously\n",
    "output_file = '../data/new_spans_labeled.json'\n",
    "checkpoint_file = '../data/checkpoint2.txt'\n",
    "label_dataset_and_save(reviews, output_file, checkpoint_file)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lowerated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
